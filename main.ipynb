{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev_halolong/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Loading data-------------\n",
      "-----------Loading data done--------\n",
      "maxpooling1 output shape:  (?, 128, 128, 64)\n",
      "maxpooling2 output shape:  (?, 64, 64, 64)\n",
      "maxpooling3 output shape:  (?, 32, 32, 64)\n",
      "maxpooling4 output shape:  (?, 16, 16, 64)\n",
      "maxpooling5 output shape:  (?, 8, 8, 64)\n",
      "upCon1 output shape:  (?, ?, ?, 64)\n",
      "upCon2 output shape:  (?, ?, ?, 64)\n",
      "upCon3 output shape:  (?, ?, ?, 64)\n",
      "upCon4 output shape:  (?, ?, ?, 64)\n",
      "upCon5 output shape:  (?, ?, ?, 64)\n",
      "out1 shape: (?, 256, 256, 1)\n",
      "out2 shape: (?, 256, 256, 1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 64) 256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 36928       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 36928       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 36928       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 64)   36928       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 64)   36928       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 64)   36928       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 64)   256         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 64)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   256         max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 64)   36928       batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   36928       batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   36928       batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 64)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     36928       batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 64)     36928       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 64)   36928       batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 128)  512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   73792       batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   36928       batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 64)   36928       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 128)  512         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 64)   73792       batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   36928       batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 64)   36928       batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 128)  512         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 64)   73792       batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 64, 64, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 64)   36928       batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 64, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 128, 128, 64) 36928       batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 128, 128, 128 512         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 128, 64) 73792       batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 128, 128, 64) 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 128, 64) 36928       batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 128, 128, 64) 256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 256, 256, 64) 36928       batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256, 256, 128 0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 256, 256, 128 512         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 256, 256, 64) 73792       batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 256, 256, 64) 256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 256, 256, 1)  65          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 256, 256, 1)  2           conv2d_28[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,339,011\n",
      "Trainable params: 1,334,403\n",
      "Non-trainable params: 4,608\n",
      "__________________________________________________________________________________________________\n",
      "-----------Fitting Model------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/20\n",
      "1440/1440 [==============================] - 52s 36ms/step - loss: 0.2651 - acc: 0.9022 - val_loss: 0.2150 - val_acc: 0.9281\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.26507, saving model to model/test2.hdf5\n",
      "Epoch 2/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.1868 - acc: 0.9319 - val_loss: 0.1774 - val_acc: 0.9387\n",
      "\n",
      "Epoch 00002: loss improved from 0.26507 to 0.18679, saving model to model/test2.hdf5\n",
      "Epoch 3/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.1593 - acc: 0.9413 - val_loss: 0.1878 - val_acc: 0.9384\n",
      "\n",
      "Epoch 00003: loss improved from 0.18679 to 0.15927, saving model to model/test2.hdf5\n",
      "Epoch 4/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.1324 - acc: 0.9508 - val_loss: 0.1666 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00004: loss improved from 0.15927 to 0.13243, saving model to model/test2.hdf5\n",
      "Epoch 5/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.1252 - acc: 0.9534 - val_loss: 0.1599 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00005: loss improved from 0.13243 to 0.12524, saving model to model/test2.hdf5\n",
      "Epoch 6/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.1063 - acc: 0.9593 - val_loss: 0.1506 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00006: loss improved from 0.12524 to 0.10630, saving model to model/test2.hdf5\n",
      "Epoch 7/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.1007 - acc: 0.9621 - val_loss: 0.1840 - val_acc: 0.9411\n",
      "\n",
      "Epoch 00007: loss improved from 0.10630 to 0.10072, saving model to model/test2.hdf5\n",
      "Epoch 8/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0887 - acc: 0.9666 - val_loss: 0.1496 - val_acc: 0.9505\n",
      "\n",
      "Epoch 00008: loss improved from 0.10072 to 0.08873, saving model to model/test2.hdf5\n",
      "Epoch 9/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0898 - acc: 0.9657 - val_loss: 0.1500 - val_acc: 0.9509\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.08873\n",
      "Epoch 10/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0743 - acc: 0.9717 - val_loss: 0.1743 - val_acc: 0.9402\n",
      "\n",
      "Epoch 00010: loss improved from 0.08873 to 0.07430, saving model to model/test2.hdf5\n",
      "Epoch 11/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0727 - acc: 0.9727 - val_loss: 0.1524 - val_acc: 0.9519\n",
      "\n",
      "Epoch 00011: loss improved from 0.07430 to 0.07272, saving model to model/test2.hdf5\n",
      "Epoch 12/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0689 - acc: 0.9738 - val_loss: 0.2996 - val_acc: 0.9272\n",
      "\n",
      "Epoch 00012: loss improved from 0.07272 to 0.06890, saving model to model/test2.hdf5\n",
      "Epoch 13/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0616 - acc: 0.9765 - val_loss: 0.1603 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00013: loss improved from 0.06890 to 0.06163, saving model to model/test2.hdf5\n",
      "Epoch 14/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0589 - acc: 0.9776 - val_loss: 0.1529 - val_acc: 0.9540\n",
      "\n",
      "Epoch 00014: loss improved from 0.06163 to 0.05895, saving model to model/test2.hdf5\n",
      "Epoch 15/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0532 - acc: 0.9796 - val_loss: 0.1881 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00015: loss improved from 0.05895 to 0.05325, saving model to model/test2.hdf5\n",
      "Epoch 16/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0496 - acc: 0.9810 - val_loss: 0.1648 - val_acc: 0.9544\n",
      "\n",
      "Epoch 00016: loss improved from 0.05325 to 0.04960, saving model to model/test2.hdf5\n",
      "Epoch 17/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0494 - acc: 0.9811 - val_loss: 0.1519 - val_acc: 0.9513\n",
      "\n",
      "Epoch 00017: loss improved from 0.04960 to 0.04942, saving model to model/test2.hdf5\n",
      "Epoch 18/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0467 - acc: 0.9820 - val_loss: 0.1614 - val_acc: 0.9502\n",
      "\n",
      "Epoch 00018: loss improved from 0.04942 to 0.04669, saving model to model/test2.hdf5\n",
      "Epoch 19/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0439 - acc: 0.9831 - val_loss: 0.1858 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00019: loss improved from 0.04669 to 0.04389, saving model to model/test2.hdf5\n",
      "Epoch 20/20\n",
      "1440/1440 [==============================] - 33s 23ms/step - loss: 0.0418 - acc: 0.9839 - val_loss: 0.1667 - val_acc: 0.9496\n",
      "\n",
      "Epoch 00020: loss improved from 0.04389 to 0.04180, saving model to model/test2.hdf5\n",
      "-----------Plotting-----------------\n",
      "-----------Predict test data--------\n",
      "10/10 [==============================] - 1s 101ms/step\n",
      "-----------Array to Image--------\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "\n",
    "\n",
    "\n",
    "# gray_data_model_1.hdf5: 保持Transpose以及1 输入gray图  数据集是gray_data_1000.npy batch 30 查看画图保存\n",
    "# gray_data_model_2.hdf5: 保持Transpose以及1 输入gray图  数据集是gray_data_1000.npy batch 14 查看画图保存\n",
    "# data_mask_2000_model_1.hdf5: 保持Transpose以及1 输入gray图  数据集是data_mask_2000_.npy batch 50 查看画图保存\n",
    "# test.hdf5: 云端运行test 保持Transpose以及1 输入gray图  数据集是data_2000_.npy batch 30 查看画图保存\n",
    "# test2.hdf5: 调整其filter为64（保持一致！） 保持Transpose以及1 输入gray图  数据集是data_2000_.npy batch 20 查看画图保存\n",
    "# 效果并不是很好，并且需要调整dropout以及阈值分割0，1出来，这样更加明显\n",
    "# TO DO\n",
    "# 优化predict.py (可以从数据读取到结果输出不需要手动每次调整)\n",
    "# 每个文件有的可以写成变量模式 全部写成变量(不要手动输入)\n",
    "# 可视化 每层activation 以及filter\n",
    "\n",
    "# problem\n",
    "# 以前的模型filter 其中没有保持一致64 有的变成了96？（所以可以尝试rgb输入的情况）\n",
    "class Main(object):\n",
    "    def __init__(self, img_rows=256, img_cols=256):\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "\n",
    "    def load_data(self):\n",
    "        train_image = np.load(\"data/data_2000_.npy\")\n",
    "        test_image = train_image\n",
    "        train_image = train_image[0:1800].astype('float') / 255\n",
    "\n",
    "        train_image_mask = np.load(\"data/data_mask_2000_.npy\")\n",
    "        test_image_mask = train_image_mask\n",
    "        train_image_mask = train_image_mask[0:1800].astype('float') / 255\n",
    "\n",
    "        test_image = test_image[1800:1810].astype('float') / 255\n",
    "\n",
    "        test_image_mask = test_image_mask[1800:1810].astype('float') / 255\n",
    "\n",
    "        return train_image, train_image_mask, test_image\n",
    "\n",
    "    def train(self):\n",
    "        print(\"-----------Loading data-------------\")\n",
    "        train_image, train_image_mask, test_image = self.load_data()\n",
    "        print('-----------Loading data done--------')\n",
    "        model1 = model.unet()\n",
    "        # plot_model(model1, to_file='/home/xingyu/Desktop/model.png', show_shapes=True)\n",
    "        model_checkpoint = ModelCheckpoint('model/test2.hdf5', monitor='loss', verbose=1, save_best_only=True)\n",
    "        print('-----------Fitting Model------------')\n",
    "        history = model1.fit(\n",
    "            train_image,\n",
    "            train_image_mask,\n",
    "            batch_size=16,\n",
    "            epochs=20,\n",
    "            verbose=1,\n",
    "            validation_split=0.2,\n",
    "            shuffle=True,\n",
    "            callbacks=[model_checkpoint]\n",
    "        )\n",
    "        print('-----------Plotting-----------------')\n",
    "        acc = history.history['acc']\n",
    "        val_acc = history.history['val_acc']\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "\n",
    "        epochs = range(1, len(acc) + 1)\n",
    "        plt.figure(num=1)\n",
    "        plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "        plt.title('Training & validation loss')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('plot/test2-loss.png')\n",
    "\n",
    "        plt.figure(num=2)\n",
    "        plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "        plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "        plt.title('Training & validation acc')\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('acc')\n",
    "        plt.legend()\n",
    "        plt.savefig('plot/test2-acc.png')\n",
    "\n",
    "        print('-----------Predict test data--------')\n",
    "        image_mask_test = model1.predict(test_image, batch_size=16, verbose=1)\n",
    "        np.save('results/test2.npy', image_mask_test)\n",
    "\n",
    "    def save_img(self):\n",
    "        print('-----------Array to Image--------')\n",
    "        imgs = np.load('results/test2.npy')\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = image.array_to_img(img)\n",
    "            img.save(\"results/test2-_%d.jpg\" % (i))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mynet = Main()\n",
    "    mynet.train()\n",
    "    mynet.save_img()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
